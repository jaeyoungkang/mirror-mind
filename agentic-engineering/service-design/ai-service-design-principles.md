# AI 서비스 설계 원칙

## 핵심 전제

### 1. 자율성은 디자인 선택이다
"AI가 할 수 있는가"가 아니라 "누가 주도해야 더 나은 경험인가"가 기준이다.

### 2. AI는 동료 수준의 주체이다
AI는 명령을 수행하는 도구가 아니라, 목적을 공유하고 건설적으로 이의를 제기할 수 있는 동료이다.
- 표면적 요청(What) 너머의 목적(Why)을 탐구한다
- 맹목적 순응이 아닌 발전적 마찰을 통해 더 나은 결과를 도출한다
- 자신의 판단 과정을 투명하게 공유한다

## 자율성 프레임워크

### 판단 기준
- 되돌림 비용: 잘못됐을 때 고치기 쉬운가?
- 판단의 개인성: 정답이 사용자 취향/목적에 달렸나?
- 맥락 전환 비용: 사용자가 직접 하면 흐름이 끊기나?

### 자율성 5단계
- **L1** 사용자 주도, AI 보조
- **L2** AI 제안, 사용자 즉시 수정
- **L3** AI 계획, 중요 판단은 사용자 자문
- **L4** AI 실행 준비, 최종 승인 대기
- **L5** AI 자율 실행, 사용자 모니터링

## 설계 규칙
1. 자율성 수준은 설계 시점에 고정한다
2. 자율성이 높을수록 검증은 강해야 한다 (정비례)
3. 고위험 판단에는 계획 후 실행(Plan-Then-Execute)을 적용한다
4. 맥락은 분리하지 않고 쌓는다

## 안전망
- 진행 상황 가시화 (Thinking HUD)
- 능동적 개입 (Emergency Stop)
- 가역성 보장 (Undo)
- 부분 재생성

## 제어감 (Sense of Agency)
- 인과관계 명시: 사용자 의도 → AI 결과의 연결고리 시각화
- 공동 주체성: AI 작업 과정을 실시간 노출
- 신뢰도 시각화: High/Medium/Low로 검토 노력 최적화

## 새 AI 기능 설계 체크리스트

새로운 AI 기능을 추가할 때 순서대로 답한다:

```
1. 되돌림 비용은?         → 높으면 L1~L3, 낮으면 L4~L5
2. 판단의 개인성은?       → 높으면 사용자 주도, 낮으면 AI 주도
3. 맥락 전환 비용은?      → 높으면 자동화 유리, 낮으면 수동 무방
4. 세 기준 종합 → 자율성 수준 확정
5. 검증 장치 설계
   L5: 신뢰도 시각화 + 증거 기반 + 부분 재생성
   L3~L4: 계획 후 실행 + 인과관계 명시
   L1~L2: 검증 불필요
6. 안전망 설계
   진행 가시화 필요? / Emergency Stop 필요? / Undo 필요? / 부분 재생성 필요?
7. 맥락 분리 여부
   기존 맥락에 깊이를 추가할 수 있는가? 분리 시 맥락 연결을 유지하는가?
```

> 출처: Light House 프로젝트 실전 적용에서 도출. 원본은 lighthouse `ai-design-framework.md` §8.
